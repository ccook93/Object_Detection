{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network\n",
    "\n",
    "1. Train\n",
    "2. Evaluate\n",
    "3. Visualize Accuracy & Lost\n",
    "4. Re-evaluate Model\n",
    "5. Make Predictions on the Test Set\n",
    "6. Visualize classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90bd2a947a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "from PIL.ImageDraw import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3a7fdedcbbcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_image_records\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_image_fullpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 6)"
     ]
    }
   ],
   "source": [
    "TRAINING_CSV_FILE = '../Data/training_data.csv'\n",
    "TRAINING_IMAGE_DIR = '../Images/Training'\n",
    "\n",
    "training_image_records = pd.read_csv(TRAINING_CSV_FILE)\n",
    "\n",
    "train_image_path = os.path.join(os.getcwd(), TRAINING_IMAGE_DIR)\n",
    "\n",
    "train_images = []\n",
    "train_targets = []\n",
    "train_labels = []\n",
    "\n",
    "for index, row in training_image_records.iterrows():\n",
    "    \n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    train_image_fullpath = os.path.join(train_image_path, filename)\n",
    "    train_img = keras.preprocessing.image.load_img(train_image_fullpath, target_size=(height, width))\n",
    "    train_img_arr = keras.preprocessing.image.img_to_array(train_img)\n",
    "    \n",
    "    \n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    train_images.append(train_img_arr)\n",
    "    train_targets.append((xmin, ymin, xmax, ymax))\n",
    "    train_labels.append(classes.index(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV_FILE = '../Data/test_data.csv'\n",
    "TEST_IMAGE_DIR = '../Images/test'\n",
    "\n",
    "test_image_records = pd.read_csv(TEST_CSV_FILE)\n",
    "\n",
    "test_image_path = os.path.join(os.getcwd(), TEST_IMAGE_DIR)\n",
    "\n",
    "test_images = []\n",
    "test_targets = []\n",
    "test_labels = []\n",
    "\n",
    "for index, row in test_image_records.iterrows():\n",
    "    \n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    test_image_fullpath = os.path.join(test_image_path, filename)\n",
    "    test_img = keras.preprocessing.image.load_img(test_image_fullpath, target_size=(height, width))\n",
    "    test_img_arr = keras.preprocessing.image.img_to_array(test_img)\n",
    "    \n",
    "    \n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    test_images.append(test_img_arr)\n",
    "    test_targets.append((xmin, ymin, xmax, ymax))\n",
    "    test_labels.append(classes.index(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_targets = np.array(train_targets)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_targets = np.array(test_targets)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 216\n",
    "height = 216\n",
    "num_classes = 2\n",
    "classes = [\"Circle\", \"No-Circle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the common input layer\n",
    "input_shape = (height, width, 3)\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "#create the base layers\n",
    "base_layers = layers.experimental.preprocessing.Rescaling(1./255, name='bl_1')(input_layer)\n",
    "base_layers = layers.Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_3')(base_layers)\n",
    "base_layers = layers.Conv2D(32, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_5')(base_layers)\n",
    "base_layers = layers.Conv2D(64, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_7')(base_layers)\n",
    "base_layers = layers.Flatten(name='bl_8')(base_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the classifier branch\n",
    "classifier_branch = layers.Dense(128, activation='relu', name='cl_1')(base_layers)\n",
    "classifier_branch = layers.Dense(num_classes, name='cl_head')(classifier_branch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input_layer,\n",
    "           outputs=[classifier_branch,locator_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = \n",
    "  {\"cl_head\":tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "   \"bb_head\":tf.keras.losses.MSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses, optimizer='Adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTargets = {\n",
    "    \"cl_head\": train_labels,\n",
    "    \"bb_head\": train_targets\n",
    "}\n",
    "validationTargets = {\n",
    "    \"cl_head\": validation_labels,\n",
    "    \"bb_head\": validation_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, trainTargets,\n",
    "             validation_data=(validation_images, validationTargets),\n",
    "             batch_size=4,\n",
    "             epochs=training_epochs,\n",
    "             shuffle=True,\n",
    "             verbose=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
